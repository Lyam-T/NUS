{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febd9490-e847-4a28-8738-9594d538b04e",
   "metadata": {},
   "source": [
    "# CS3244, Machine Learning, Semester 1, 2024/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da488f-a0f3-442e-a598-9a1ec87bd3f5",
   "metadata": {},
   "source": [
    "### PARITY\n",
    "We will experiment with using nearest neighbour to do prediction for **PARITY** under two input distributions: \n",
    "1. Uniform distribution, and \n",
    "2. Uniform distribution over instances with at most two nonzero inputs.\n",
    "\n",
    "Using a 20 dimensional input, we will randomly select 10,000 training examples.\n",
    "\n",
    "Before running the experiment, enter your prediction of the outcome in Archipelago:<br>\n",
    "A. Nearest neighbour does WELL on both (1) and (2).<br>\n",
    "B. Nearest neighbour does WELL on (1) but POORLY on (2). <br>\n",
    "C. Nearest neighbour does POORLY on (1) but WELL on (2).<br>\n",
    "D. Nearest neighbour does POORLY  on both (1) and (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff679cac-be83-4cdb-8b4d-19ac51fe8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for uniform distribution: 0.69\n",
      "Test set accuracy for uniform distribution over instances with at most 2 nonzero inputs: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_size = 10000\n",
    "test_size = 1000\n",
    "input_size = 20\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Construct training and test sets\n",
    "# Uniform input distribution\n",
    "train_data1 = np.random.randint(2,size=(train_size,input_size))\n",
    "train_label1 = train_data1.sum(axis=1)%2\n",
    "test_data1 = np.random.randint(2,size=(test_size,input_size))\n",
    "test_label1 = test_data1.sum(axis=1)%2 # compute PARITY\n",
    "# Uniform distribution over instances with at most two nonzero inputs\n",
    "train_data2 = np.zeros((train_size,input_size))\n",
    "for i in range(0,train_size):\n",
    "    num_ones = np.random.randint(3)\n",
    "    curr = np.array([1] * num_ones + [0] * (input_size - num_ones))\n",
    "    np.random.shuffle(curr)\n",
    "    train_data2[i] = curr\n",
    "train_label2 = train_data2.sum(axis=1)%2\n",
    "test_data2 = np.zeros((test_size,input_size))\n",
    "for i in range(0,test_size):\n",
    "    num_ones = np.random.randint(3)\n",
    "    curr = np.array([1] * num_ones + [0] * (input_size - num_ones))\n",
    "    np.random.shuffle(curr)\n",
    "    test_data2[i] = curr\n",
    "test_label2 = test_data2.sum(axis=1)%2\n",
    "\n",
    "# Run nearest neighbour classifier\n",
    "clf1 = neighbors.KNeighborsClassifier(1)\n",
    "clf1.fit(train_data1, train_label1)\n",
    "predict1 = clf1.predict(test_data1)\n",
    "clf2 = neighbors.KNeighborsClassifier(1)\n",
    "clf2.fit(train_data2, train_label2)\n",
    "predict1 = clf1.predict(test_data1)\n",
    "accuracy1 = accuracy_score(test_label1, predict1)\n",
    "predict2 = clf2.predict(test_data2)\n",
    "accuracy2 = accuracy_score(test_label2, predict2)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Test set accuracy for uniform distribution: \" + \"{0:.2f}\".format(accuracy1))\n",
    "print(\"Test set accuracy for uniform distribution over instances with at most 2 nonzero inputs: \" + \"{0:.2f}\".format(accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae017e-810e-40af-b80a-f8ea5704d035",
   "metadata": {},
   "source": [
    "## Feature Selection for NN\n",
    "\n",
    "Do you think doing feature selection would be helpful when using nearest neighbour for text classification? Why? Answer with a phrase before running the experiment.\n",
    "\n",
    "We will use the 20 Newsgroup dataset in the experiment. TF-IDF representation is used for feature representation. Chi square method is used for feature selection. Feature engineering and feature selection will be covered later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca38dedd-9051-4988-af93-0322ee1c732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with no feature selection: 0.39\n",
      "Accuracy with 10 features: 0.42\n",
      "Accuracy with 50 features: 0.55\n",
      "Accuracy with 100 features: 0.56\n",
      "Accuracy with 500 features: 0.56\n",
      "Accuracy with 1000 features: 0.54\n",
      "Accuracy with 5000 features: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Select only 4 categories to speed things up\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "\n",
    "# Fetch training and test sets\n",
    "twenty_train = fetch_20newsgroups(subset='train', remove=('headers','footers','quotes'),\n",
    "                                  categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', remove=('headers','footers','quotes'),\n",
    "                                 categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Use tfidf\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "vectors = vectorizer.fit_transform(twenty_train.data)\n",
    "vectors_test = vectorizer.transform(twenty_test.data)\n",
    "\n",
    "# No feature selection\n",
    "clf = neighbors.KNeighborsClassifier(1)\n",
    "clf.fit(vectors, twenty_train.target)\n",
    "predict = clf.predict(vectors_test)\n",
    "accuracy = accuracy_score(twenty_test.target, predict)\n",
    "print(\"Accuracy with no feature selection: \" + \"{0:.2f}\".format(accuracy))\n",
    "\n",
    "# Feature selection with different number of features selected\n",
    "fs_num = [10, 50, 100, 500, 1000, 5000]\n",
    "for i in fs_num:\n",
    "    fs = SelectKBest(chi2, k=i)\n",
    "    vectors_fs = fs.fit_transform(vectors, twenty_train.target)\n",
    "    vectors_test_fs = fs.transform(vectors_test)\n",
    "    clf = neighbors.KNeighborsClassifier(1)\n",
    "    clf.fit(vectors_fs, twenty_train.target)\n",
    "    predict = clf.predict(vectors_test_fs)\n",
    "    accuracy = accuracy_score(twenty_test.target, predict)\n",
    "    print(\"Accuracy with \" + str(i) + \" features: \" + \"{0:.2f}\".format(accuracy))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd195712-0f31-41ba-a2a8-c12657dc1975",
   "metadata": {},
   "source": [
    "## Normalization for NN\n",
    "\n",
    "The previous experiment did not do normalization. Do you think doing normalization would be helpful when using nearest neighbour for text classification? Why? Answer with a phrase before running the experiment.\n",
    "\n",
    "Now, rerun with normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee645a3c-3ca5-465d-a2ca-ac05c14e6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tfidf\n",
    "vectorizer = TfidfVectorizer(norm='l2') # Use l2 normalization\n",
    "vectors = vectorizer.fit_transform(twenty_train.data)\n",
    "vectors_test = vectorizer.transform(twenty_test.data)\n",
    "\n",
    "# No feature selection\n",
    "clf = neighbors.KNeighborsClassifier(1)\n",
    "clf.fit(vectors, twenty_train.target)\n",
    "predict = clf.predict(vectors_test)\n",
    "accuracy = accuracy_score(twenty_test.target, predict)\n",
    "print(\"Accuracy with no feature selection: \" + \"{0:.2f}\".format(accuracy))\n",
    "\n",
    "# Feature selection with different number of features selected\n",
    "fs_num = [50, 100, 500, 1000, 5000]\n",
    "for i in fs_num:\n",
    "    fs = SelectKBest(chi2, k=i)\n",
    "    vectors_fs = fs.fit_transform(vectors, twenty_train.target)\n",
    "    vectors_test_fs = fs.transform(vectors_test)\n",
    "    clf = neighbors.KNeighborsClassifier(1)\n",
    "    clf.fit(vectors_fs, twenty_train.target)\n",
    "    predict = clf.predict(vectors_test_fs)\n",
    "    accuracy = accuracy_score(twenty_test.target, predict)\n",
    "    print(\"Accuracy with \" + str(i) + \" features: \" + \"{0:.2f}\".format(accuracy))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1440d0e-0989-408f-8d66-119e21f9631f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
